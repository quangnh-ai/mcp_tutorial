{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langsmith import utils\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Generic, TypeVar\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.environ[\"GOOGLE_AI_KEY\"]\n",
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro-exp-03-25\",\n",
    "    api_key=API_KEY\n",
    ")\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizza dough (store-bought or homemade)', 'Pizza sauce', 'Shredded mozzarella cheese', 'Toppings (e.g., pepperoni, mushrooms, bell peppers, onions)', 'Olive oil', 'Cornmeal (optional, for dusting)', 'Flour (for dusting)']\n",
      "[KeyValueStep[str, str](key='step_1', value='Preheat your oven to 475째F (245째C). If using a pizza stone or steel, place it in the oven now. Lightly dust a pizza peel or the back of a baking sheet with cornmeal or flour to prevent sticking.'), KeyValueStep[str, str](key='step_2', value='On a lightly floured surface, stretch or roll out the pizza dough to your desired thickness (usually 12-14 inches round). Carefully transfer the dough onto the prepared pizza peel or baking sheet.'), KeyValueStep[str, str](key='step_3', value='Brush the edge of the dough lightly with olive oil (optional, for a crispier crust). Spread a layer of pizza sauce evenly over the dough, leaving about a half-inch border for the crust.'), KeyValueStep[str, str](key='step_4', value='Sprinkle the shredded mozzarella cheese generously and evenly over the sauce.'), KeyValueStep[str, str](key='step_5', value=\"Add your favorite toppings over the cheese. Don't overload it, as this can make the crust soggy.\"), KeyValueStep[str, str](key='step_6', value='Carefully slide the pizza from the peel onto the preheated pizza stone/steel, or place the baking sheet directly onto the oven rack. Bake for 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and slightly browned.'), KeyValueStep[str, str](key='step_7', value='Using the peel or oven mitts, carefully remove the pizza from the oven. Let it rest for 2-3 minutes before slicing and serving. Enjoy your homemade pizza!')]\n",
      "{'gradients': ['Pizza dough (store-bought or homemade)', 'Pizza sauce', 'Shredded mozzarella cheese', 'Toppings (e.g., pepperoni, mushrooms, bell peppers, onions)', 'Olive oil', 'Cornmeal (optional, for dusting)', 'Flour (for dusting)'], 'steps': {'step_1': 'Preheat your oven to 475째F (245째C). If using a pizza stone or steel, place it in the oven now. Lightly dust a pizza peel or the back of a baking sheet with cornmeal or flour to prevent sticking.', 'step_2': 'On a lightly floured surface, stretch or roll out the pizza dough to your desired thickness (usually 12-14 inches round). Carefully transfer the dough onto the prepared pizza peel or baking sheet.', 'step_3': 'Brush the edge of the dough lightly with olive oil (optional, for a crispier crust). Spread a layer of pizza sauce evenly over the dough, leaving about a half-inch border for the crust.', 'step_4': 'Sprinkle the shredded mozzarella cheese generously and evenly over the sauce.', 'step_5': \"Add your favorite toppings over the cheese. Don't overload it, as this can make the crust soggy.\", 'step_6': 'Carefully slide the pizza from the peel onto the preheated pizza stone/steel, or place the baking sheet directly onto the oven rack. Bake for 10-15 minutes, or until the crust is golden brown and the cheese is bubbly and slightly browned.', 'step_7': 'Using the peel or oven mitts, carefully remove the pizza from the oven. Let it rest for 2-3 minutes before slicing and serving. Enjoy your homemade pizza!'}}\n"
     ]
    }
   ],
   "source": [
    "TKey = TypeVar(\"TKey\")\n",
    "TValue = TypeVar(\"TValue\")\n",
    "class KeyValueStep(BaseModel, Generic[TKey, TValue]):\n",
    "    key: TKey\n",
    "    value: TValue\n",
    "\n",
    "    def to_list(self) -> List[TValue]:\n",
    "        return [self.key, self.value]\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            self.key: self.value\n",
    "        }\n",
    "\n",
    "class CookingRecipe(BaseModel):\n",
    "    gradients: List[str] = Field(description=\"gradients which needed to cook the dish\")\n",
    "    steps: List[KeyValueStep[str, str]] = Field(description=\"Step by step how to make the dish\")\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        steps = [step.to_list() for step in self.steps]\n",
    "        steps = {\n",
    "            step[0]: step[1] for step in steps\n",
    "        }\n",
    "        return {\n",
    "            \"gradients\": self.gradients,\n",
    "            \"steps\": steps\n",
    "        }\n",
    "\n",
    "structured_llm = llm_model.with_structured_output(CookingRecipe)\n",
    "prompt = \"\"\"You are a professional chef, your duty is receiving request from user about a dish and answer how to cook that in a format.\n",
    "You need to return 2 things: \n",
    " - First is required gradients, return as a list with each element is each gradient for the dish\n",
    " - Second is step by step how to cook the dish, return as a list, each element is a list of 2 strings, first is step order and second is the content of that step\n",
    " for the step order, you need to return like this step_1, step_2, step_3, ... return it as a normal string\n",
    "Example:\n",
    "- Gradients: [\"flour\", \"sugar\", \"egg\", \"milk\", ...]\n",
    "- Steps: [[\"step_1\", \"Mix flour and sugar together\"], [\"step_2\", \"Add egg and milk to the mixture\"], ...]\n",
    "The request from user: {user_request}\n",
    "Return your answer here:\n",
    "\"\"\"\n",
    "answer: CookingRecipe = structured_llm.invoke(\n",
    "    prompt.format(\n",
    "        user_request=\"pizza\"\n",
    "    )\n",
    ")\n",
    "print(answer.gradients)\n",
    "print(answer.steps)\n",
    "print(answer.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "groundino trex 2 paper\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_arxiv_papers (02ca1aa3-f6d2-4dc2-bf39-d865ce401473)\n",
      " Call ID: 02ca1aa3-f6d2-4dc2-bf39-d865ce401473\n",
      "  Args:\n",
      "    query: groundino trex 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_arxiv_papers\n",
      "\n",
      "[\"{\\\"id\\\": null, \\\"metadata\\\": {\\\"Entry ID\\\": \\\"http://arxiv.org/abs/1404.0541v3\\\", \\\"Published\\\": \\\"2015-05-24\\\", \\\"Title\\\": \\\"Don't Fall for Tuning Parameters: Tuning-Free Variable Selection in High Dimensions With the TREX\\\", \\\"Authors\\\": \\\"Johannes Lederer, Christian M\\\\u00fcller\\\"}, \\\"page_content\\\": \\\"Lasso is a seminal contribution to high-dimensional statistics, but it hinges\\\\non a tuning parameter that is difficult to calibrate in practice. A partial\\\\nremedy for this problem is Square-Root Lasso, because it inherently calibrates\\\\nto the noise variance. However, Square-Root Lasso still requires the\\\\ncalibration of a tuning parameter to all other aspects of the model. In this\\\\nstudy, we introduce TREX, an alternative to Lasso with an inherent calibration\\\\nto all aspects of the model. This adaptation to the entire model renders TREX\\\\nan estimator that does not require any calibration of tuning parameters. We\\\\nshow that TREX can outperform cross-validated Lasso in terms of variable\\\\nselection and computational efficiency. We also introduce a bootstrapped\\\\nversion of TREX that can further improve variable selection. We illustrate the\\\\npromising performance of TREX both on synthetic data and on a recent\\\\nhigh-dimensional biological data set that considers riboflavin production in B.\\\\nsubtilis.\\\", \\\"type\\\": \\\"Document\\\"}\", \"{\\\"id\\\": null, \\\"metadata\\\": {\\\"Entry ID\\\": \\\"http://arxiv.org/abs/2408.12742v1\\\", \\\"Published\\\": \\\"2024-08-22\\\", \\\"Title\\\": \\\"TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing\\\", \\\"Authors\\\": \\\"Abhishek Moitra, Abhiroop Bhattacharjee, Youngeun Kim, Priyadarshini Panda\\\"}, \\\"page_content\\\": \\\"Due to the high computation overhead of Vision Transformers (ViTs), In-memory\\\\nComputing architectures are being researched towards energy-efficient\\\\ndeployment in edge-computing scenarios. Prior works have proposed efficient\\\\nalgorithm-hardware co-design and IMC-architectural improvements to improve the\\\\nenergy-efficiency of IMC-implemented ViTs. However, all prior works have\\\\nneglected the overhead and co-depencence of attention blocks on the\\\\naccuracy-energy-delay-area of IMC-implemented ViTs. To this end, we propose\\\\nTReX- an attention-reuse-driven ViT optimization framework that effectively\\\\nperforms attention reuse in ViT models to achieve optimal\\\\naccuracy-energy-delay-area tradeoffs. TReX optimally chooses the transformer\\\\nencoders for attention reuse to achieve near iso-accuracy performance while\\\\nmeeting the user-specified delay requirement. Based on our analysis on the\\\\nImagenet-1k dataset, we find that TReX achieves 2.3x (2.19x) EDAP reduction and\\\\n1.86x (1.79x) TOPS/mm2 improvement with ~1% accuracy drop in case of DeiT-S\\\\n(LV-ViT-S) ViT models. Additionally, TReX achieves high accuracy at high EDAP\\\\nreduction compared to state-of-the-art token pruning and weight sharing\\\\napproaches. On NLP tasks such as CoLA, TReX leads to 2% higher non-ideal\\\\naccuracy compared to baseline at 1.6x lower EDAP.\\\", \\\"type\\\": \\\"Document\\\"}\", \"{\\\"id\\\": null, \\\"metadata\\\": {\\\"Entry ID\\\": \\\"http://arxiv.org/abs/1801.01394v1\\\", \\\"Published\\\": \\\"2018-01-04\\\", \\\"Title\\\": \\\"Prediction Error Bounds for Linear Regression With the TREX\\\", \\\"Authors\\\": \\\"Jacob Bien, Irina Gaynanova, Johannes Lederer, Christian M\\\\u00fcller\\\"}, \\\"page_content\\\": \\\"The TREX is a recently introduced approach to sparse linear regression. In\\\\ncontrast to most well-known approaches to penalized regression, the TREX can be\\\\nformulated without the use of tuning parameters. In this paper, we establish\\\\nthe first known prediction error bounds for the TREX. Additionally, we\\\\nintroduce extensions of the TREX to a more general class of penalties, and we\\\\nprovide a bound on the prediction error in this generalized setting. These\\\\nresults deepen the understanding of TREX from a theoretical perspective and\\\\nprovide new insights into penalized regression in general.\\\", \\\"type\\\": \\\"Document\\\"}\"]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I found a few papers on arXiv related to \"TREX\", but none specifically mention \"groundino trex 2\".\n",
      "\n",
      "Here are the summaries:\n",
      "\n",
      "1.  **TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing** (Published 2024-08-22): This paper proposes TReX, a framework to optimize Vision Transformers (ViTs) by reusing attention mechanisms for better energy efficiency, particularly for edge computing using In-memory Computing (IMC) architectures. It aims to improve accuracy-energy-delay-area trade-offs.\n",
      "2.  **Don't Fall for Tuning Parameters: Tuning-Free Variable Selection in High Dimensions With the TREX** (Published 2015-05-24): This paper introduces TREX as an alternative to Lasso for high-dimensional variable selection that inherently calibrates to the model, avoiding the need for tuning parameters.\n",
      "3.  **Prediction Error Bounds for Linear Regression With the TREX** (Published 2018-01-04): This paper establishes theoretical prediction error bounds for the TREX method in sparse linear regression and introduces extensions.\n",
      "\n",
      "Could \"groundino\" be a typo, or is \"trex 2\" part of a specific project or model name? The most recent paper deals with Vision Transformers, which might be relevant depending on the context you're interested in.\n"
     ]
    }
   ],
   "source": [
    "async with MultiServerMCPClient() as client:\n",
    "    await client.connect_to_server(\n",
    "        server_name=\"math\",\n",
    "        transport=\"sse\",\n",
    "        url=\"http://localhost:8000/sse\",\n",
    "    )\n",
    "    await client.connect_to_server(\n",
    "        server_name=\"Arxiv\",\n",
    "        transport=\"sse\",\n",
    "        url=\"http://localhost:9000/sse\",\n",
    "    )\n",
    "    await client.connect_to_server(\n",
    "        server_name=\"Wikipedia\",\n",
    "        transport=\"sse\",\n",
    "        url=\"http://localhost:6000/sse\",\n",
    "    )\n",
    "    agent = create_react_agent(model=llm_model, tools=client.get_tools())\n",
    "    user_question = \"groundino trex 2 paper\"\n",
    "    response = await agent.ainvoke({\"messages\": user_question})\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
